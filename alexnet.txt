import os
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

from tensorflow import keras
from tensorflow.python.keras.api._v2.keras import layers, optimizers, losses
from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Dropout, Flatten, Dense
from tensorflow.keras import Model
from tensorflow.keras.callbacks import EarlyStopping
from    tensorflow.keras import layers, optimizers,losses, datasets, Sequential
from PIL import Image

tf.random.set_seed(22)
np.random.seed(22)
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
assert tf.__version__.startswith('2.')

# 导入一些具体的工具
from gender import  load_gender, normalize,denormalize

# 预处理的函数
def preprocess(x,y):
    # x: 图片的路径，y：图片的数字编码
    x = tf.io.read_file(x)
    x = tf.image.decode_jpeg(x, channels=3) # RGBA
    x = tf.image.resize(x, [224, 224])

    x = tf.cast(x, dtype=tf.float32) / 255.
    x = normalize(x)
    y = tf.convert_to_tensor(y)
    y = tf.one_hot(y, depth=2)

    return x, y

batchsz = 16

# creat train db   一般训练的时候需要shuffle。其它是不需要的。
images, labels, table = load_gender('gender',mode='train')
db_train = tf.data.Dataset.from_tensor_slices((images, labels))  # 变成个Dataset对象。
db_train = db_train.shuffle(1000).map(preprocess).batch(batchsz) # map函数图片路径变为内容。
# crate validation db
images2, labels2, table = load_gender('gender',mode='val')
db_val = tf.data.Dataset.from_tensor_slices((images2, labels2))
db_val = db_val.map(preprocess).batch(batchsz)
# create test db
images3, labels3, table = load_gender('gender',mode='test')
db_test = tf.data.Dataset.from_tensor_slices((images3, labels3))
db_test = db_test.map(preprocess).batch(batchsz)


model = tf.keras.Sequential ([
    layers.Conv2D(64, (5, 5),strides=2, input_shape=(224, 224, 3)),
    layers.BatchNormalization(),
    layers.Activation('relu'),
    layers.MaxPool2D(pool_size=3,strides=2),

    layers.Conv2D(128, (3, 3)),
    layers.BatchNormalization(),
    layers.Activation('relu'),
    layers.MaxPool2D(pool_size=3,strides=2),

    layers.Conv2D(196, (3, 3),padding='same'),
    layers.BatchNormalization(),
    layers.Activation('relu'),

    layers.Conv2D(196, (3, 3),padding='same'),
    layers.BatchNormalization(),
    layers.Activation('relu'),

    layers.Conv2D(128, (3, 3),padding='same'),
    layers.BatchNormalization(),
    layers.Activation('relu'),
    layers.MaxPool2D(pool_size=3,strides=2),

    layers.GlobalAveragePooling2D(),


    layers.Dense(2,activation='softmax')
])

model.summary()

# 网络的装配。
exponential_decay = tf.keras.optimizers.schedules.ExponentialDecay(
                        initial_learning_rate=0.001, decay_steps=88, decay_rate=0.90)



model.compile(optimizer=optimizers.Adam(exponential_decay),
               loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),
               metrics=['acc'])

# 完成标准的train，val, test;
# 标准的逻辑必须通过db_val挑选模型的参数，就需要提供一个earlystopping技术，
history = model.fit(db_train, validation_data=db_val, validation_freq=1, epochs=60,
                    )   # 1个epoch验证1次。触发了这个事情，提前停止了。
model.evaluate(db_test)
model.save('AlexNet.h5')

plt.subplot(1, 2, 1)
plt.plot(history.epoch, history.history.get('acc'),label='acc')
plt.plot(history.epoch, history.history.get('val_acc'),label='val_acc')
plt.title('Training and Validation Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.epoch, history.history.get('loss'),label='loss')
plt.plot(history.epoch, history.history.get('val_loss'),label='val_loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()